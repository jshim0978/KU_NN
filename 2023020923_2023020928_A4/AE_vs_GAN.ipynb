{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part1 Autoencoders (30 points):\n",
    "\n",
    "<p>\n",
    "Your first task is to adapt the code from class to create a CNN-based autoencoder instead of the fully-connected one. \n",
    "\n",
    "Take a look at the DCGAN example to see how to use the upconvolution.\n",
    "\n",
    "Use three conv layers with 32, 64, 128 for the encoder. \n",
    "\n",
    "The dimensionality of the latent space should be flexible as an input to the constructor and set per default to 100. \n",
    "\n",
    "Use 128, 64, 32 as your symmetric decoder.\n",
    "\n",
    "Run the autoencoder on MNIST for 20 epochs with Adam and lr=0.001, using the standard MSE loss and with a latent space dimensionality of d = 2.\n",
    "\n",
    "Now visualize each digit of the trainset of MNIST in the latent space similar to how we did this in class.\n",
    "\n",
    "What can you say about the clustering of digits? \n",
    "\n",
    "Compare this to the fully-connected version from class? \n",
    "\n",
    "Do you think the CNN-version of the AE is better??\n",
    "\n",
    "Re-train the autoencoder with a latent space of d = 10 and d = 50 and compare the MSE-loss for all three autoencoders, as well as discuss the quality of reconstruction.\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torchvision as tv\n",
    "from torchvision import transforms, utils\n",
    "import glob\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_FC(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AE_FC,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "class AE_FC_deep(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AE_FC_deep,self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    # we define this function so we can access only the\n",
    "    # latent space of the model\n",
    "    def getlatent(self,x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_CNN(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(AE_CNN, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 128, kernel_size=3,stride=2, padding=1, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Conv2d(128, latent_dim, kernel_size=1, stride=1, padding=1, bias=False), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 128, kernel_size=1, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128), \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, bias=False),      \n",
    "            nn.BatchNorm2d(64),      \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False), \n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1, bias=False),  \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def get_latent(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = tv.datasets.MNIST(root='./',  train=True,download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
    "testset = tv.datasets.MNIST(root='./', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertBatchToCombined(inp,out):\n",
    "    # this should be extended to arbitrary batch length\n",
    "    # assuming this to be 10 here\n",
    "    combinedUp = np.zeros((28,28*10))\n",
    "    combinedDown = np.zeros((28,28*10))\n",
    "    for b in np.arange(10):\n",
    "        combinedUp[:,b*28:b*28+28]=np.reshape(inp[:,b],(28,28))\n",
    "        combinedDown[:,b*28:b*28+28]=np.reshape(out[:,b],(28,28))\n",
    "    tmp = np.vstack([combinedUp,combinedDown])\n",
    "    tmp = (tmp-tmp.min())/(tmp.max()-tmp.min())*255.\n",
    "    return(np.repeat(tmp[:,:,np.newaxis], 3, axis=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9204b6fe6b31409ca491038d2aba7d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'type': 'image',\n",
       "              'uid': 'a7a20a65-2b35-4e72-bbbc-515fa218084a',\n",
       "              'xaxis': 'x',\n",
       "              'yaxis': 'y',\n",
       "              'z': array([[[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]],\n",
       "                   \n",
       "                          [[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]],\n",
       "                   \n",
       "                          [[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]],\n",
       "                   \n",
       "                          ...,\n",
       "                   \n",
       "                          [[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]],\n",
       "                   \n",
       "                          [[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]],\n",
       "                   \n",
       "                          [[0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           ...,\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.],\n",
       "                           [0., 0., 0.]]])}],\n",
       "    'layout': {'autosize': False,\n",
       "               'height': 800,\n",
       "               'template': '...',\n",
       "               'width': 1000,\n",
       "               'xaxis': {'anchor': 'y', 'domain': [0.0, 1.0], 'showticklabels': False},\n",
       "               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'showticklabels': False}}\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.append_trace(go.Image(z=np.zeros((28,28*10,3))),row=1,col=1)\n",
    "fig = go.FigureWidget(fig)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=800,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/20], loss:0.0448\n",
      "epoch [2/20], loss:0.0429\n",
      "epoch [3/20], loss:0.0423\n",
      "epoch [4/20], loss:0.0364\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "model = AE_FC_deep(2)\n",
    "\n",
    "# put to device\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "    else torch.device('cpu'))\n",
    "\n",
    "model.to(device=device)\n",
    "\n",
    "# use MSE loss\n",
    "distance = nn.MSELoss()\n",
    "\n",
    "# standard ADAM\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# pre-load the test pictures for visualization of online prediction\n",
    "timg, tlabels = list(dataloader)[0]\n",
    "timg = timg.to(device)\n",
    "timg = timg.view(timg.size(0), -1)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, data in enumerate(dataloader):\n",
    "        # we don't need the labels here\n",
    "        img, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # flatten\n",
    "        img = img.view(img.size(0), -1)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss_mse = distance(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss_mse.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # visualize output\n",
    "        if (n_batch) % 50 == 0:\n",
    "            with torch.no_grad():\n",
    "                output = model(timg)\n",
    "                inp = timg[0:10, :].detach().cpu()\n",
    "                out = output[0:10, :].detach().cpu()\n",
    "\n",
    "                combined = convertBatchToCombined(inp.permute(1,0),out.permute(1,0))\n",
    "\n",
    "                with fig.batch_update():\n",
    "                    fig.data[0]['z'] = combined\n",
    "                    fig.update_layout(\n",
    "                        title={\n",
    "                            'text':'epoch {0:} batch {1:} L={2: .3f}'.format(\n",
    "                                epoch+1,n_batch,loss_mse.item()),\n",
    "                            'xanchor':'center',\n",
    "                            'x':0.5\n",
    "                        })\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss_mse.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_AE_CNN(num_epochs, latent_dim):\n",
    "    model = AE_CNN(latent_dim)\n",
    "\n",
    "    device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "        else torch.device('cpu'))\n",
    "\n",
    "    model.to(device=device)\n",
    "\n",
    "    # use MSE loss\n",
    "    distance = nn.MSELoss()\n",
    "\n",
    "    # standard ADAM\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # List to store loss values\n",
    "    epoch_losses = []\n",
    "    \n",
    "    timg, tlabels = list(dataloader)[0]\n",
    "    timg = timg.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        batch_count = 0\n",
    "\n",
    "        for n_batch, data in enumerate(dataloader):\n",
    "            # we don't need the labels here\n",
    "            img, labels = data[0].to(device), data[1].to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(img)\n",
    "            loss_mse = distance(output, img)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss_mse.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss_mse.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            # visualize output\n",
    "            if (n_batch) % 50 == 0:\n",
    "                with torch.no_grad():\n",
    "                    output = model(timg)\n",
    "                    inp = timg[0:10, :].detach().cpu()\n",
    "                    out = output[0:10, :].detach().cpu()\n",
    "                    #Since our input has a structure of (128,1,28,28) we need to reshape it to put into model\n",
    "                    combined = convertBatchToCombined(inp.permute(1,0,2,3),out.permute(1,0,2,3))\n",
    "                \n",
    "                    with fig.batch_update():\n",
    "                        fig.data[0]['z'] = combined\n",
    "                        fig.update_layout(\n",
    "                            title={\n",
    "                                'text':'epoch {0:} batch {1:} L={2: .3f}'.format(\n",
    "                                    epoch+1,n_batch,loss_mse.item()),\n",
    "                                'xanchor':'center',\n",
    "                                'x':0.5\n",
    "                            })\n",
    "        average_loss = epoch_loss / batch_count\n",
    "        epoch_losses.append(average_loss)\n",
    "\n",
    "        # ===================log========================\n",
    "        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss_mse.item()))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    dataloaderSorted = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=False, num_workers=4)\n",
    "\n",
    "    for n_batch, data in enumerate(dataloaderSorted):\n",
    "        img, labels = data[0].to(device), data[1].detach().cpu().numpy()\n",
    "\n",
    "    # don't forget to do this\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    # go through each label\n",
    "    for l in np.arange(10):\n",
    "        # find the indices\n",
    "        inds = labels==l\n",
    "        # select the images\n",
    "        tmp = img[inds,:,:,:]\n",
    "        tmp.to(device)\n",
    "        # flatten them\n",
    "        #tmp = tmp.view(tmp.size(0), -1)\n",
    "        # put them through the model to get their 2D latent\n",
    "        # space representation\n",
    "        output = model.get_latent(tmp).detach().cpu().numpy()\n",
    "        # and scatter giving the label as the digit string\n",
    "        plt.scatter(output[:,0],output[:,1],label=str(l))\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    return epoch_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.append_trace(go.Image(z=np.zeros((28,28*10,3))),row=1,col=1)\n",
    "fig = go.FigureWidget(fig)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=1000,\n",
    "    height=600,\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing MSE Loss Across Different Latent Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 20\n",
    "latent_dims = [2, 10, 20] \n",
    "losses_per_dim = {}\n",
    "\n",
    "for dim in latent_dims:\n",
    "    print(f\"Training with latent_dim = {dim}\")\n",
    "    losses = train_AE_CNN(num_epochs, dim)\n",
    "    losses_per_dim[dim] = losses\n",
    "    \n",
    "for latent_dim, losses in losses_per_dim.items():\n",
    "    plt.plot(losses, label=f'latent_dim={latent_dim}')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('MSE Loss over Epochs for Different latent_dims')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2 Autoencoders vs GANs (30 points):\n",
    "Still using the same notebook, add a DCGAN and train this on MNIST using a\n",
    "comparable number of conv-layers, making sure to end up with DCGAN\n",
    "architectures that use SIMILAR number of parameters compared to the\n",
    "Neural Networks, Prof. C. Wallraven Page 2 of 2\n",
    "autoencoders. Again, produce three different DCGAN models using generator\n",
    "spaces of d = 2, d = 10, d = 50 training for n=20 epochs with properly set learning\n",
    "rates.\n",
    "Answer these questions:\n",
    "1. Can you visualize the “latent” space of the DCGAN in the same way as the\n",
    "autoencoder? Explain!\n",
    "2. Which of the methods produces “better” digits?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(128*4*4, latent_dim, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Flatten and apply sigmoid\n",
    "        x = x.view(-1, 128 * 4 * 4, 1, 1)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    # reset weights\n",
    "    def reset(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.reset_parameters()\n",
    "                m.weight.data.normal_(0.00, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_plotly(arr):\n",
    "    tmp = (arr-arr.min())/(arr.max()-arr.min())*255\n",
    "    return np.dstack((tmp,tmp,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorNet(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Initial linear layers to create a starting point for convolution\n",
    "        self.conv0 = nn.ConvTranspose2d(latent_dim, 128 * 4 * 4, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=4, stride=2, padding=1),\n",
    "        )\n",
    "        self.out = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Project and reshape\n",
    "        x = x.view(x.shape[0], latent_dim, 1, 1)\n",
    "        x = self.conv0(x)\n",
    "        x = x.view(x.shape[0], 128, 4, 4)\n",
    "\n",
    "        # Convolutional layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        #Apply Tanh\n",
    "        return self.out(x)\n",
    "\n",
    "    # reset weights\n",
    "    def reset(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                m.reset_parameters()\n",
    "                m.weight.data.normal_(0.00, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Noise\n",
    "def noise(size, latent_dim):\n",
    "    n = torch.randn(size, latent_dim)\n",
    "    if torch.cuda.is_available(): return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size, latent_dim):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = torch.ones(size, latent_dim, 1, 1)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size, latent_dim):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = torch.zeros(size, latent_dim, 1, 1)\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def train_discriminator(optimizer, real_data, fake_data, latent_dim):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    # Error is measured against real data targets\n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0), latent_dim))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    # Error is measured against fake targets\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0), latent_dim))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data, latent_dim):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    # Note that here the error is pretending to be real\n",
    "    error = loss(prediction, real_data_target(prediction.size(0), latent_dim))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 50\n",
    "test_noise = noise(num_test_samples, 100)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10,5))\n",
    "ax.imshow(test_noise.cpu())\n",
    "ax.set_xlabel('feature dimensions')\n",
    "ax.set_ylabel('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact\n",
    "fig = make_subplots(rows=4, cols=4)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        fig.append_trace(go.Image(z=np.zeros((32,32,3))),row=i+1,col=j+1)\n",
    "fig = go.FigureWidget(fig)\n",
    "fig.update_xaxes(showticklabels=False)\n",
    "fig.update_yaxes(showticklabels=False)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "discriminator = DiscriminatorNet(latent_dim)\n",
    "generator = GeneratorNet(latent_dim)\n",
    "\n",
    "# summary(discriminator, torch.zeros((1, 1, 32, 32)), show_input=True)\n",
    "# summary(generator, torch.zeros((1, 10, 1, 1)), show_input=True)\n",
    "\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "\n",
    "discriminator.to(device=device)\n",
    "generator.to(device=device)\n",
    "\n",
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "discriminator.reset()\n",
    "generator.reset()\n",
    "\n",
    "# Number of epochs for training the GAN\n",
    "num_epochs = 20\n",
    "\n",
    "t_start = time.time()\n",
    "duration_avg = 0.0\n",
    "\n",
    "\n",
    "test_noise = noise(num_test_samples, latent_dim)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, real_data in enumerate(dataloader):\n",
    "        # 1. Train Discriminator with real images\n",
    "        if torch.cuda.is_available():real_data[0] = real_data[0].to(device)\n",
    "        # Generate fake data from noise, do not update\n",
    "        # gradients here - hence add \".detach()\"\n",
    "        noi = noise(real_data[0].size(0), latent_dim)\n",
    "        fake_data = generator(noi).detach()\n",
    "        # Train discriminator with the real and fake data\n",
    "        d_error, d_pred_real, d_pred_fake = \\\n",
    "                            train_discriminator(d_optimizer,                                    \n",
    "                            real_data[0].float(), fake_data, latent_dim)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data from noise\n",
    "        fake_data = generator(noi)#noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data, latent_dim)\n",
    "        # Display Progress\n",
    "        if (n_batch) % 50 == 0:\n",
    "            test_images = generator(test_noise).data.cpu()\n",
    "            p=0\n",
    "            with fig.batch_update():\n",
    "                for i in range(4):\n",
    "                    for j in range(4):\n",
    "                        tmp=test_images[p,0,:,:].numpy()\n",
    "                        fig.data[p]['z']=numpy_to_plotly(tmp)\n",
    "                        p+=1\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text':'epoch {0:} batch {1:} L(D)={2: .3f} L(G)={3: .3f} t={4: .1f}s/it'.format(\n",
    "                        epoch,n_batch,d_error,g_error,duration_avg),\n",
    "                    'xanchor':'center',\n",
    "                    'x':0.5\n",
    "                })\n",
    "                \n",
    "    t_end = time.time()\n",
    "    duration_avg = (t_end - t_start) / (epoch + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaderSorted = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=False, num_workers=4)\n",
    "\n",
    "for n_batch, data in enumerate(dataloaderSorted):\n",
    "    img, labels = data[0].to(device), data[1].detach().cpu().numpy()\n",
    "plt.figure(figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't forget to do this\n",
    "discriminator.eval()\n",
    "discriminator.to(device)\n",
    "# go through each label\n",
    "for l in np.arange(10):\n",
    "    # find the indices\n",
    "    inds = labels==l\n",
    "    # select the images\n",
    "    tmp = img[inds,:,:,:]\n",
    "    tmp.to(device)\n",
    "    # flatten them\n",
    "    #tmp = tmp.view(tmp.size(0), -1)\n",
    "    # put them through the model to get their 2D latent\n",
    "    # space representation\n",
    "    output = discriminator.forward(tmp).detach().cpu().numpy()\n",
    "    # and scatter giving the label as the digit string\n",
    "    plt.scatter(output[:,0],output[:,1],label=str(l))\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "discriminator = DiscriminatorNet(latent_dim)\n",
    "generator = GeneratorNet(latent_dim)\n",
    "\n",
    "# summary(discriminator, torch.zeros((1, 1, 32, 32)), show_input=True)\n",
    "# summary(generator, torch.zeros((1, 10, 1, 1)), show_input=True)\n",
    "\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "\n",
    "discriminator.to(device=device)\n",
    "generator.to(device=device)\n",
    "\n",
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "discriminator.reset()\n",
    "generator.reset()\n",
    "\n",
    "# Number of epochs for training the GAN\n",
    "num_epochs = 20\n",
    "\n",
    "t_start = time.time()\n",
    "duration_avg = 0.0\n",
    "\n",
    "\n",
    "test_noise = noise(num_test_samples, latent_dim)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, real_data in enumerate(dataloader):\n",
    "        # 1. Train Discriminator with real images\n",
    "        if torch.cuda.is_available():real_data[0] = real_data[0].to(device)\n",
    "        # Generate fake data from noise, do not update\n",
    "        # gradients here - hence add \".detach()\"\n",
    "        noi = noise(real_data[0].size(0), latent_dim)\n",
    "        fake_data = generator(noi).detach()\n",
    "        # Train discriminator with the real and fake data\n",
    "        d_error, d_pred_real, d_pred_fake = \\\n",
    "                            train_discriminator(d_optimizer,                                    \n",
    "                            real_data[0].float(), fake_data, latent_dim)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data from noise\n",
    "        fake_data = generator(noi)#noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data, latent_dim)\n",
    "        # Display Progress\n",
    "        if (n_batch) % 50 == 0:\n",
    "            test_images = generator(test_noise).data.cpu()\n",
    "            p=0\n",
    "            with fig.batch_update():\n",
    "                for i in range(4):\n",
    "                    for j in range(4):\n",
    "                        tmp=test_images[p,0,:,:].numpy()\n",
    "                        fig.data[p]['z']=numpy_to_plotly(tmp)\n",
    "                        p+=1\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text':'epoch {0:} batch {1:} L(D)={2: .3f} L(G)={3: .3f} t={4: .1f}s/it'.format(\n",
    "                        epoch,n_batch,d_error,g_error,duration_avg),\n",
    "                    'xanchor':'center',\n",
    "                    'x':0.5\n",
    "                })\n",
    "                \n",
    "    t_end = time.time()\n",
    "    duration_avg = (t_end - t_start) / (epoch + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "latent_dim = 50\n",
    "\n",
    "discriminator = DiscriminatorNet(latent_dim)\n",
    "generator = GeneratorNet(latent_dim)\n",
    "\n",
    "# summary(discriminator, torch.zeros((1, 1, 32, 32)), show_input=True)\n",
    "# summary(generator, torch.zeros((1, 10, 1, 1)), show_input=True)\n",
    "\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')\n",
    "\n",
    "discriminator.to(device=device)\n",
    "generator.to(device=device)\n",
    "\n",
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "discriminator.reset()\n",
    "generator.reset()\n",
    "\n",
    "# Number of epochs for training the GAN\n",
    "num_epochs = 20\n",
    "\n",
    "t_start = time.time()\n",
    "duration_avg = 0.0\n",
    "\n",
    "\n",
    "test_noise = noise(num_test_samples, latent_dim)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, real_data in enumerate(dataloader):\n",
    "        # 1. Train Discriminator with real images\n",
    "        if torch.cuda.is_available():real_data[0] = real_data[0].to(device)\n",
    "        # Generate fake data from noise, do not update\n",
    "        # gradients here - hence add \".detach()\"\n",
    "        noi = noise(real_data[0].size(0), latent_dim)\n",
    "        fake_data = generator(noi).detach()\n",
    "        # Train discriminator with the real and fake data\n",
    "        d_error, d_pred_real, d_pred_fake = \\\n",
    "                            train_discriminator(d_optimizer,                                    \n",
    "                            real_data[0].float(), fake_data, latent_dim)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data from noise\n",
    "        fake_data = generator(noi)#noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data, latent_dim)\n",
    "        # Display Progress\n",
    "        if (n_batch) % 50 == 0:\n",
    "            test_images = generator(test_noise).data.cpu()\n",
    "            p=0\n",
    "            with fig.batch_update():\n",
    "                for i in range(4):\n",
    "                    for j in range(4):\n",
    "                        tmp=test_images[p,0,:,:].numpy()\n",
    "                        fig.data[p]['z']=numpy_to_plotly(tmp)\n",
    "                        p+=1\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text':'epoch {0:} batch {1:} L(D)={2: .3f} L(G)={3: .3f} t={4: .1f}s/it'.format(\n",
    "                        epoch,n_batch,d_error,g_error,duration_avg),\n",
    "                    'xanchor':'center',\n",
    "                    'x':0.5\n",
    "                })\n",
    "                \n",
    "    t_end = time.time()\n",
    "    duration_avg = (t_end - t_start) / (epoch + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KU_NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
